# coding: utf-8

"""
    Akeyless API

    The purpose of this application is to provide access to Akeyless API.  # noqa: E501

    The version of the OpenAPI document: 3.0
    Contact: support@akeyless.io
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from akeyless.configuration import Configuration


class CreateTokenizer(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'alphabet': 'str',
        'decoding_template': 'str',
        'delete_protection': 'str',
        'description': 'str',
        'encoding_template': 'str',
        'encryption_key_name': 'str',
        'json': 'bool',
        'metadata': 'str',
        'name': 'str',
        'pattern': 'str',
        'tag': 'list[str]',
        'template_type': 'str',
        'token': 'str',
        'tokenizer_type': 'str',
        'tweak_type': 'str',
        'uid_token': 'str'
    }

    attribute_map = {
        'alphabet': 'alphabet',
        'decoding_template': 'decoding-template',
        'delete_protection': 'delete_protection',
        'description': 'description',
        'encoding_template': 'encoding-template',
        'encryption_key_name': 'encryption-key-name',
        'json': 'json',
        'metadata': 'metadata',
        'name': 'name',
        'pattern': 'pattern',
        'tag': 'tag',
        'template_type': 'template-type',
        'token': 'token',
        'tokenizer_type': 'tokenizer-type',
        'tweak_type': 'tweak-type',
        'uid_token': 'uid-token'
    }

    def __init__(self, alphabet=None, decoding_template=None, delete_protection=None, description=None, encoding_template=None, encryption_key_name=None, json=False, metadata=None, name=None, pattern=None, tag=None, template_type=None, token=None, tokenizer_type='vaultless', tweak_type=None, uid_token=None, local_vars_configuration=None):  # noqa: E501
        """CreateTokenizer - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._alphabet = None
        self._decoding_template = None
        self._delete_protection = None
        self._description = None
        self._encoding_template = None
        self._encryption_key_name = None
        self._json = None
        self._metadata = None
        self._name = None
        self._pattern = None
        self._tag = None
        self._template_type = None
        self._token = None
        self._tokenizer_type = None
        self._tweak_type = None
        self._uid_token = None
        self.discriminator = None

        if alphabet is not None:
            self.alphabet = alphabet
        if decoding_template is not None:
            self.decoding_template = decoding_template
        if delete_protection is not None:
            self.delete_protection = delete_protection
        if description is not None:
            self.description = description
        if encoding_template is not None:
            self.encoding_template = encoding_template
        if encryption_key_name is not None:
            self.encryption_key_name = encryption_key_name
        if json is not None:
            self.json = json
        if metadata is not None:
            self.metadata = metadata
        self.name = name
        if pattern is not None:
            self.pattern = pattern
        if tag is not None:
            self.tag = tag
        self.template_type = template_type
        if token is not None:
            self.token = token
        self.tokenizer_type = tokenizer_type
        if tweak_type is not None:
            self.tweak_type = tweak_type
        if uid_token is not None:
            self.uid_token = uid_token

    @property
    def alphabet(self):
        """Gets the alphabet of this CreateTokenizer.  # noqa: E501

        Alphabet to use in regexp vaultless tokenization  # noqa: E501

        :return: The alphabet of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._alphabet

    @alphabet.setter
    def alphabet(self, alphabet):
        """Sets the alphabet of this CreateTokenizer.

        Alphabet to use in regexp vaultless tokenization  # noqa: E501

        :param alphabet: The alphabet of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._alphabet = alphabet

    @property
    def decoding_template(self):
        """Gets the decoding_template of this CreateTokenizer.  # noqa: E501

        The Decoding output template to use in regexp vaultless tokenization  # noqa: E501

        :return: The decoding_template of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._decoding_template

    @decoding_template.setter
    def decoding_template(self, decoding_template):
        """Sets the decoding_template of this CreateTokenizer.

        The Decoding output template to use in regexp vaultless tokenization  # noqa: E501

        :param decoding_template: The decoding_template of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._decoding_template = decoding_template

    @property
    def delete_protection(self):
        """Gets the delete_protection of this CreateTokenizer.  # noqa: E501

        Protection from accidental deletion of this object [true/false]  # noqa: E501

        :return: The delete_protection of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._delete_protection

    @delete_protection.setter
    def delete_protection(self, delete_protection):
        """Sets the delete_protection of this CreateTokenizer.

        Protection from accidental deletion of this object [true/false]  # noqa: E501

        :param delete_protection: The delete_protection of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._delete_protection = delete_protection

    @property
    def description(self):
        """Gets the description of this CreateTokenizer.  # noqa: E501

        Description of the object  # noqa: E501

        :return: The description of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._description

    @description.setter
    def description(self, description):
        """Sets the description of this CreateTokenizer.

        Description of the object  # noqa: E501

        :param description: The description of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._description = description

    @property
    def encoding_template(self):
        """Gets the encoding_template of this CreateTokenizer.  # noqa: E501

        The Encoding output template to use in regexp vaultless tokenization  # noqa: E501

        :return: The encoding_template of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._encoding_template

    @encoding_template.setter
    def encoding_template(self, encoding_template):
        """Sets the encoding_template of this CreateTokenizer.

        The Encoding output template to use in regexp vaultless tokenization  # noqa: E501

        :param encoding_template: The encoding_template of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._encoding_template = encoding_template

    @property
    def encryption_key_name(self):
        """Gets the encryption_key_name of this CreateTokenizer.  # noqa: E501

        AES key name to use in vaultless tokenization  # noqa: E501

        :return: The encryption_key_name of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._encryption_key_name

    @encryption_key_name.setter
    def encryption_key_name(self, encryption_key_name):
        """Sets the encryption_key_name of this CreateTokenizer.

        AES key name to use in vaultless tokenization  # noqa: E501

        :param encryption_key_name: The encryption_key_name of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._encryption_key_name = encryption_key_name

    @property
    def json(self):
        """Gets the json of this CreateTokenizer.  # noqa: E501

        Set output format to JSON  # noqa: E501

        :return: The json of this CreateTokenizer.  # noqa: E501
        :rtype: bool
        """
        return self._json

    @json.setter
    def json(self, json):
        """Sets the json of this CreateTokenizer.

        Set output format to JSON  # noqa: E501

        :param json: The json of this CreateTokenizer.  # noqa: E501
        :type: bool
        """

        self._json = json

    @property
    def metadata(self):
        """Gets the metadata of this CreateTokenizer.  # noqa: E501

        Deprecated - use description  # noqa: E501

        :return: The metadata of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._metadata

    @metadata.setter
    def metadata(self, metadata):
        """Sets the metadata of this CreateTokenizer.

        Deprecated - use description  # noqa: E501

        :param metadata: The metadata of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._metadata = metadata

    @property
    def name(self):
        """Gets the name of this CreateTokenizer.  # noqa: E501

        Tokenizer name  # noqa: E501

        :return: The name of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this CreateTokenizer.

        Tokenizer name  # noqa: E501

        :param name: The name of this CreateTokenizer.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and name is None:  # noqa: E501
            raise ValueError("Invalid value for `name`, must not be `None`")  # noqa: E501

        self._name = name

    @property
    def pattern(self):
        """Gets the pattern of this CreateTokenizer.  # noqa: E501

        Pattern to use in regexp vaultless tokenization  # noqa: E501

        :return: The pattern of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._pattern

    @pattern.setter
    def pattern(self, pattern):
        """Sets the pattern of this CreateTokenizer.

        Pattern to use in regexp vaultless tokenization  # noqa: E501

        :param pattern: The pattern of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._pattern = pattern

    @property
    def tag(self):
        """Gets the tag of this CreateTokenizer.  # noqa: E501

        List of the tags attached to this key  # noqa: E501

        :return: The tag of this CreateTokenizer.  # noqa: E501
        :rtype: list[str]
        """
        return self._tag

    @tag.setter
    def tag(self, tag):
        """Sets the tag of this CreateTokenizer.

        List of the tags attached to this key  # noqa: E501

        :param tag: The tag of this CreateTokenizer.  # noqa: E501
        :type: list[str]
        """

        self._tag = tag

    @property
    def template_type(self):
        """Gets the template_type of this CreateTokenizer.  # noqa: E501

        Which template type this tokenizer is used for [SSN,CreditCard,USPhoneNumber,Email,Regexp]  # noqa: E501

        :return: The template_type of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._template_type

    @template_type.setter
    def template_type(self, template_type):
        """Sets the template_type of this CreateTokenizer.

        Which template type this tokenizer is used for [SSN,CreditCard,USPhoneNumber,Email,Regexp]  # noqa: E501

        :param template_type: The template_type of this CreateTokenizer.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and template_type is None:  # noqa: E501
            raise ValueError("Invalid value for `template_type`, must not be `None`")  # noqa: E501

        self._template_type = template_type

    @property
    def token(self):
        """Gets the token of this CreateTokenizer.  # noqa: E501

        Authentication token (see `/auth` and `/configure`)  # noqa: E501

        :return: The token of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._token

    @token.setter
    def token(self, token):
        """Sets the token of this CreateTokenizer.

        Authentication token (see `/auth` and `/configure`)  # noqa: E501

        :param token: The token of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._token = token

    @property
    def tokenizer_type(self):
        """Gets the tokenizer_type of this CreateTokenizer.  # noqa: E501

        Tokenizer type  # noqa: E501

        :return: The tokenizer_type of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._tokenizer_type

    @tokenizer_type.setter
    def tokenizer_type(self, tokenizer_type):
        """Sets the tokenizer_type of this CreateTokenizer.

        Tokenizer type  # noqa: E501

        :param tokenizer_type: The tokenizer_type of this CreateTokenizer.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and tokenizer_type is None:  # noqa: E501
            raise ValueError("Invalid value for `tokenizer_type`, must not be `None`")  # noqa: E501

        self._tokenizer_type = tokenizer_type

    @property
    def tweak_type(self):
        """Gets the tweak_type of this CreateTokenizer.  # noqa: E501

        The tweak type to use in vaultless tokenization [Supplied, Generated, Internal, Masking]  # noqa: E501

        :return: The tweak_type of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._tweak_type

    @tweak_type.setter
    def tweak_type(self, tweak_type):
        """Sets the tweak_type of this CreateTokenizer.

        The tweak type to use in vaultless tokenization [Supplied, Generated, Internal, Masking]  # noqa: E501

        :param tweak_type: The tweak_type of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._tweak_type = tweak_type

    @property
    def uid_token(self):
        """Gets the uid_token of this CreateTokenizer.  # noqa: E501

        The universal identity token, Required only for universal_identity authentication  # noqa: E501

        :return: The uid_token of this CreateTokenizer.  # noqa: E501
        :rtype: str
        """
        return self._uid_token

    @uid_token.setter
    def uid_token(self, uid_token):
        """Sets the uid_token of this CreateTokenizer.

        The universal identity token, Required only for universal_identity authentication  # noqa: E501

        :param uid_token: The uid_token of this CreateTokenizer.  # noqa: E501
        :type: str
        """

        self._uid_token = uid_token

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, CreateTokenizer):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, CreateTokenizer):
            return True

        return self.to_dict() != other.to_dict()
